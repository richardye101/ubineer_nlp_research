{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976d94f9-3448-4382-8e39-2482dda4cadb",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/timeseries_data_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maimport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_func\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/preprocessed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m data_t \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/timeseries_data_2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/timeseries_data_2.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport std_func\n",
    "\n",
    "data = pd.read_csv(\"../data/preprocessed.csv\")\n",
    "data_t = pd.read_csv(\"../data/timeseries_data_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d60cd3e-a212-4d5d-b232-1ec47ef3d375",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filingDate</th>\n",
       "      <th>financialEntity</th>\n",
       "      <th>coDescription</th>\n",
       "      <th>CIK</th>\n",
       "      <th>coDescription_lemmatized</th>\n",
       "      <th>coDescription_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-02-28T00:42:30Z</td>\n",
       "      <td>financialEntities/params;cik=1065280</td>\n",
       "      <td>we are the largest online movie rentalsubscrip...</td>\n",
       "      <td>1065280</td>\n",
       "      <td>we are the largest online movie rentalsubscrip...</td>\n",
       "      <td>largest online movie rentalsubscription servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-02-25T21:22:45Z</td>\n",
       "      <td>financialEntities/params;cik=1065280</td>\n",
       "      <td>with more than 10 millionsubscribers, we are t...</td>\n",
       "      <td>1065280</td>\n",
       "      <td>with more than 10 millionsubscribers , we are ...</td>\n",
       "      <td>millionsubscribers largest online movie rental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-22T19:09:32Z</td>\n",
       "      <td>financialEntities/params;cik=1065280</td>\n",
       "      <td>with more than12 million subscribers, we are t...</td>\n",
       "      <td>1065280</td>\n",
       "      <td>with more than12 million subscriber , we are t...</td>\n",
       "      <td>million subscriber world largest subscription ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-18T19:42:40Z</td>\n",
       "      <td>financialEntities/params;cik=1065280</td>\n",
       "      <td>us with 20 million subscribers as of december ...</td>\n",
       "      <td>1065280</td>\n",
       "      <td>u with 20 million subscriber a of december 31 ...</td>\n",
       "      <td>u million subscriber december netflix netflix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-10T22:29:24Z</td>\n",
       "      <td>financialEntities/params;cik=1065280</td>\n",
       "      <td>us netflix inc. (“netflix”, “the company”, “we...</td>\n",
       "      <td>1065280</td>\n",
       "      <td>u netflix inc. ( “ netflix ” , “ the company ”...</td>\n",
       "      <td>u netflix netflix company u world leading inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             filingDate                       financialEntity  \\\n",
       "0  2008-02-28T00:42:30Z  financialEntities/params;cik=1065280   \n",
       "1  2009-02-25T21:22:45Z  financialEntities/params;cik=1065280   \n",
       "2  2010-02-22T19:09:32Z  financialEntities/params;cik=1065280   \n",
       "3  2011-02-18T19:42:40Z  financialEntities/params;cik=1065280   \n",
       "4  2012-02-10T22:29:24Z  financialEntities/params;cik=1065280   \n",
       "\n",
       "                                       coDescription      CIK  \\\n",
       "0  we are the largest online movie rentalsubscrip...  1065280   \n",
       "1  with more than 10 millionsubscribers, we are t...  1065280   \n",
       "2  with more than12 million subscribers, we are t...  1065280   \n",
       "3  us with 20 million subscribers as of december ...  1065280   \n",
       "4  us netflix inc. (“netflix”, “the company”, “we...  1065280   \n",
       "\n",
       "                            coDescription_lemmatized  \\\n",
       "0  we are the largest online movie rentalsubscrip...   \n",
       "1  with more than 10 millionsubscribers , we are ...   \n",
       "2  with more than12 million subscriber , we are t...   \n",
       "3  u with 20 million subscriber a of december 31 ...   \n",
       "4  u netflix inc. ( “ netflix ” , “ the company ”...   \n",
       "\n",
       "                             coDescription_stopwords  \n",
       "0  largest online movie rentalsubscription servic...  \n",
       "1  millionsubscribers largest online movie rental...  \n",
       "2  million subscriber world largest subscription ...  \n",
       "3  u million subscriber december netflix netflix ...  \n",
       "4  u netflix netflix company u world leading inte...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_five = pd.DataFrame.from_dict(\n",
    "    {1660134:\"OKTA\",1713683:\"Z-Scaler\",1065280:\"NFLX\",51143:\"IBM\",40545:\"GE\"},\n",
    "    orient = \"index\").reset_index().rename(columns={\"index\":\"CIK\",0:\"name\"})\n",
    "\n",
    "data_five_raw = pd.read_csv(\"../data/bq_dynamic_five.csv\")\n",
    "data_five_raw[\"CIK\"] = data_five_raw[\"financialEntity\"].str.split(\"=\", expand = True).iloc[:,1]\n",
    "data_five = std_func.clean(data_five_raw)\n",
    "data_five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a189077-ac81-40a7-bcf8-b26e3ce3f5b0",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The companies with names have them, the ones that don't are NaN\u001b[39;00m\n\u001b[1;32m      2\u001b[0m clean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m----> 3\u001b[0m     pd\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mdata_t\u001b[49m,data\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     the_five, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_y\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_x\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m clean \u001b[38;5;241m=\u001b[39m clean\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreports\u001b[39m\u001b[38;5;124m\"\u001b[39m],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_t' is not defined"
     ]
    }
   ],
   "source": [
    "# The companies with names have them, the ones that don't are NaN\n",
    "clean = pd.merge(\n",
    "    pd.merge(data_t,data.loc[:,[\"CIK\",\"name\"]], how = \"left\", on = \"CIK\"),\n",
    "    the_five, how = \"left\", on=\"CIK\")\n",
    "\n",
    "clean['name'] = clean['name_y'].fillna(clean['name_x'])\n",
    "clean = clean.drop([\"name_x\",\"name_y\",\"reports\"],axis = 1)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72e559d-309a-4c41-9d8c-ac05c9234650",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mclean\u001b[49m,data_five], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m final \u001b[38;5;241m=\u001b[39m final\u001b[38;5;241m.\u001b[39mmerge(pd\u001b[38;5;241m.\u001b[39mSeries(final\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msize(), name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreports\u001b[39m\u001b[38;5;124m\"\u001b[39m), how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilingDate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      3\u001b[0m final\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean' is not defined"
     ]
    }
   ],
   "source": [
    "final = pd.concat([clean,data_five], axis = 0)\n",
    "final = final.merge(pd.Series(final.groupby(\"CIK\").size(), name = \"reports\"), how = \"left\", on = \"CIK\").sort_values([\"CIK\",\"filingDate\"]).reset_index()\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b736c32a-a0ef-485b-95a4-b6c162134769",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from datetime import datetime\n",
    "\n",
    "def deltas(final, embedding, features):\n",
    "    ignore_words = [\"revenue\",\"fiscal\",\"year\", \"operating\", \"december\", \"ended\", \"administrative\", \"month\", \"company\", \"general\", \"also\",\n",
    "                    \"statement\", \"asset\", \"result\", \"term\", \"september\", \"accounting\", \"million\"]\n",
    "    changes = [[],[],[],[]]\n",
    "    for i in final.loc[:,\"CIK\"]:\n",
    "        # i = final.loc[2,\"CIK\"]\n",
    "        # Get the all company filings\n",
    "        company_filings = embedding[embedding[\"CIK\"] == i].reset_index(drop=True)\n",
    "        # Get the change YoY in tfidf values\n",
    "        delta = pd.DataFrame(np.array(company_filings.iloc[1:,3:]) - np.array(company_filings.iloc[:-1,3:]), columns=features)\n",
    "        # named_delta = pd.concat([company_filings.loc[1:,[\"filingDate\",\"CIK\", \"name\"]].reset_index(drop=True),delta], axis = 1)\n",
    "        # Get the top 20 changed terms in YoY filings\n",
    "        for j in np.arange(company_filings.shape[0]-1):\n",
    "            word_delta = delta.iloc[j,:].sort_values(key=abs, ascending = False).reset_index()\n",
    "            word_delta['flagCol'] = np.where(word_delta.loc[:,\"index\"].str.contains('|'.join(ignore_words)),1,0)\n",
    "            words = word_delta[word_delta['flagCol'] == 0].iloc[:,:2].head(20).reset_index(drop=True).rename(columns = {\"index\":\"topic\",0:\"delta\"})\n",
    "            # year = datetime.strptime(company_filings.loc[j,\"filingDate\"], '%Y-%m-%d %H:%M:%S UTC').date().year\n",
    "            info = pd.concat([pd.Series(i).repeat(20),pd.Series(str(\"year \" + j + \" to year \" + int(j+1))).repeat(20)], axis = 1) \\\n",
    "                .reset_index(drop=True)\\\n",
    "                .rename(columns = {0:\"CIK\",1:\"years\"})\n",
    "            to_append = pd.concat([info,words], axis = 1)\n",
    "            for k in np.arange(to_append.shape[1]):\n",
    "                changes[k].append(to_append.iloc[:,k].tolist())\n",
    "\n",
    "    for i in np.arange(len(changes)):\n",
    "        changes[i] = functools.reduce(operator.iconcat, changes[i], [])\n",
    "        \n",
    "    return(pd.DataFrame(list(zip(changes[0],changes[1],changes[2],changes[3]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51463540-831c-4824-b100-287fdeccc86d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# combine the techniques since tf-idf only augments count vectorized documents\u001b[39;00m\n\u001b[1;32m      6\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, CountVectorizer(ngram_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m), max_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m)),\n\u001b[0;32m----> 7\u001b[0m                   (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfTransformer())])\u001b[38;5;241m.\u001b[39mfit(\u001b[43mfinal\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoDescription_stopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(pipe\u001b[38;5;241m.\u001b[39mtransform(final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoDescription_stopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[1;32m     10\u001b[0m data_tfidf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([final\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilingDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]],tfidf], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# combine the techniques since tf-idf only augments count vectorized documents\n",
    "pipe = Pipeline([('count', CountVectorizer(ngram_range = (2,4), max_features = 1000)),\n",
    "                  ('tfidf', TfidfTransformer())]).fit(final[\"coDescription_stopwords\"])\n",
    "\n",
    "tfidf = pd.DataFrame(pipe.transform(final[\"coDescription_stopwords\"]).toarray())\n",
    "data_tfidf = pd.concat([final.loc[:,[\"filingDate\",\"CIK\", \"name\"]],tfidf], axis = 1)\n",
    "delta_tfidf = deltas(final, data_tfidf, pipe.get_feature_names_out().tolist())\n",
    "delta_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a654dd6-d30a-494e-ad45-fdcc9ff7851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1660134</td>\n",
       "      <td>OKTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1713683</td>\n",
       "      <td>Z-Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1065280</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51143</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40545</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIK      name\n",
       "0  1660134      OKTA\n",
       "1  1713683  Z-Scaler\n",
       "2  1065280      NFLX\n",
       "3    51143       IBM\n",
       "4    40545        GE"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee81438-5a0e-4eb8-8309-ab571185bbd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delta_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# OKTA\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdelta_tfidf\u001b[49m[delta_tfidf\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1660134\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m60\u001b[39m,:]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'delta_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# OKTA\n",
    "delta_tfidf[delta_tfidf.iloc[:,0] == 1660134].iloc[:60,:].groupby(1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd9cf30-fc3d-4d31-ab99-3547456d7346",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delta_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Z-Scaler\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdelta_tfidf\u001b[49m[delta_tfidf\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1713683\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m60\u001b[39m,:]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'delta_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Z-Scaler\n",
    "delta_tfidf[delta_tfidf.iloc[:,0] == 1713683].iloc[:60,:].groupby(1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9674e1c-9072-4d94-bff5-47ee670ccaa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal\u001b[49m[final[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1065280\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "final[final[\"CIK\"] == 1065280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b280fca-9229-42ef-b82d-3db5ed7e69f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delta_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Netflix\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdelta_tfidf\u001b[49m[delta_tfidf\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1065280\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m60\u001b[39m,:]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'delta_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Netflix\n",
    "delta_tfidf[delta_tfidf.iloc[:,0] == 1065280].iloc[:60,:].groupby(1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "956ba57b-1b3a-431f-ae59-8f5e72270468",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'delta_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# GE\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdelta_tfidf\u001b[49m[delta_tfidf\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m40545\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m60\u001b[39m,:]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'delta_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# GE\n",
    "delta_tfidf[delta_tfidf.iloc[:,0] == 40545].iloc[:60,:].groupby(1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4af095-1042-4b1b-97aa-5a094b5a54b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:source:1: no such file or directory: /Users/richardye/Documents/Python/venv_ubineer/bin/activate\r\n"
     ]
    }
   ],
   "source": [
    "!source /Users/richardye/Documents/Python/venv_ubineer/bin/activate\n",
    "# !pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a90cf58f-af19-49b3-8745-1163801cac62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mword2vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m----> 4\u001b[0m revs_processed \u001b[38;5;241m=\u001b[39m \u001b[43mfinal\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoDescription_stopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: utils\u001b[38;5;241m.\u001b[39msimple_preprocess(x))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# https://stackoverflow.com/questions/46560861/relation-between-word2vec-vector-size-and-total-number-of-words-scanned\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_w \u001b[38;5;241m=\u001b[39m Word2Vec(revs_processed, vector_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim import utils\n",
    "\n",
    "revs_processed = final[\"coDescription_stopwords\"].apply(lambda x: utils.simple_preprocess(x))\n",
    "\n",
    "# https://stackoverflow.com/questions/46560861/relation-between-word2vec-vector-size-and-total-number-of-words-scanned\n",
    "model_w = Word2Vec(revs_processed, vector_size = 300)\n",
    "\n",
    "def doc_to_vec(text):\n",
    "    word_vecs = [model_w.wv[w] for w in text if w in model_w.wv]\n",
    "    \n",
    "    if len(word_vecs) == 0:\n",
    "        return np.zeros(model_w.vector_size)\n",
    "    \n",
    "    return np.mean(word_vecs, axis = 0)\n",
    "\n",
    "doc_vec = pd.DataFrame(revs_processed.apply(doc_to_vec).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75ae1371-1829-42fd-8755-a7dbe2fe80f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdoc_vec\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_vec' is not defined"
     ]
    }
   ],
   "source": [
    "doc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3414de31-b562-431f-9414-2c1af1f8b5c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m first_yr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mfinal\u001b[49m\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilingDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]],doc_vec],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(first_yr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m first_yr\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "first_yr = pd.concat([final.loc[:,[\"filingDate\",\"CIK\", \"name\"]],doc_vec],axis = 1).groupby(\"CIK\").head(1)\n",
    "print(first_yr.shape)\n",
    "first_yr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07c35868-b147-40c4-a5f2-fc5bb2a16786",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_yr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n\u001b[0;32m----> 3\u001b[0m clustering \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.05\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(\u001b[43mfirst_yr\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m:])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_yr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clustering = DBSCAN(eps=.05, min_samples=5, metric='cosine').fit(first_yr.iloc[:,3:])\n",
    "# clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d9b4c3e-dcd1-4b1b-9fd1-8097567548e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclustering\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\u001b[38;5;241m.\u001b[39mmax()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clustering' is not defined"
     ]
    }
   ],
   "source": [
    "clustering.labels_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b34aa6-cd3e-4299-85bb-67e670f74706",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unique_elements, counts_elements \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mclustering\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency of unique values of the said array:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39masarray((unique_elements, counts_elements)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clustering' is not defined"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(clustering.labels_, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb9a164-d327-466c-b203-aebfe2fa62e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_yr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m centers_w2v \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mfirst_yr\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m:],pd\u001b[38;5;241m.\u001b[39mSeries(clustering\u001b[38;5;241m.\u001b[39mlabels_, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m)], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \\\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      3\u001b[0m centers_w2v\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_yr' is not defined"
     ]
    }
   ],
   "source": [
    "centers_w2v = pd.concat([first_yr.iloc[:,3:],pd.Series(clustering.labels_, name = \"cluster\")], axis = 1) \\\n",
    "    .groupby(\"cluster\").mean()\n",
    "centers_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3456df14-42e1-4783-8962-0b0e846dbc35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_yr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# get distances to each cluster center created based on first year filings\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# want to find representative companies for each cluster\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m cosine_dist \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mfirst_yr\u001b[49m\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilingDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      5\u001b[0m                          pd\u001b[38;5;241m.\u001b[39mDataFrame(cosine_similarity(first_yr\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m:],centers_w2v))],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m cosine_dist\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_yr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# get distances to each cluster center created based on first year filings\n",
    "# want to find representative companies for each cluster\n",
    "cosine_dist = pd.concat([first_yr.loc[:,[\"filingDate\",\"CIK\", \"name\"]].reset_index(drop=True),\n",
    "                         pd.DataFrame(cosine_similarity(first_yr.iloc[:,3:],centers_w2v))],axis = 1)\n",
    "cosine_dist\n",
    "# pd.concat([first_yr.loc[:,[\"filingDate\",\"CIK\", \"name\"]],\n",
    "#            pd.DataFrame(cosine_similarity(first_yr.iloc[:,3:],centers_w2v))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "678ebc83-ee6b-4426-9344-5b148a7f7bcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cluster_companies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m3\u001b[39m,\u001b[43mcosine_dist\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     rank \u001b[38;5;241m=\u001b[39m cosine_dist\u001b[38;5;241m.\u001b[39miloc[:,i]\u001b[38;5;241m.\u001b[39msort_values(ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m      4\u001b[0m     CIK \u001b[38;5;241m=\u001b[39m first_yr\u001b[38;5;241m.\u001b[39miloc[rank,\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosine_dist' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_companies = []\n",
    "for i in np.arange(3,cosine_dist.shape[1]):\n",
    "    rank = cosine_dist.iloc[:,i].sort_values(ascending = False).index.tolist()[:5]\n",
    "    CIK = first_yr.iloc[rank,1]\n",
    "    rep_words = final[final[\"CIK\"].isin(CIK)].groupby(\"CIK\").head(1).loc[:,\"coDescription\"]\n",
    "    cluster_companies.append(rep_words)\n",
    "cluster_companies[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e08288a-db72-4db1-9724-7b69dd3f1a1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_w2v \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mfinal\u001b[49m\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilingDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]],doc_vec],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m yr_2_dist \u001b[38;5;241m=\u001b[39m all_w2v[all_w2v\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcumcount() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m yr_3_dist \u001b[38;5;241m=\u001b[39m all_w2v[all_w2v\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcumcount() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "all_w2v = pd.concat([final.loc[:,[\"filingDate\",\"CIK\", \"name\"]],doc_vec],axis = 1)\n",
    "yr_2_dist = all_w2v[all_w2v.groupby(\"CIK\").cumcount() == 1]\n",
    "yr_3_dist = all_w2v[all_w2v.groupby(\"CIK\").cumcount() == 2]\n",
    "\n",
    "cosine_dist_2 = pd.concat([yr_2_dist.loc[:,[\"filingDate\",\"CIK\", \"name\"]].reset_index(drop=True),\n",
    "                           pd.DataFrame(cosine_similarity(yr_2_dist.iloc[:,3:],centers_w2v))],axis = 1)\n",
    "cosine_dist_3 = pd.concat([yr_3_dist.loc[:,[\"filingDate\",\"CIK\", \"name\"]].reset_index(drop=True),\n",
    "                           pd.DataFrame(cosine_similarity(yr_3_dist.iloc[:,3:],centers_w2v))],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab3088c0-6a02-46ce-8be3-daf1693d0b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_dist_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y1_y2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mcosine_dist_2\u001b[49m[cosine_dist_2\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(cosine_dist\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m:]) \u001b[38;5;241m-\u001b[39m \\\n\u001b[1;32m      2\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(cosine_dist[cosine_dist\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(cosine_dist_2\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m:]),\n\u001b[1;32m      3\u001b[0m                      index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_frame(pd\u001b[38;5;241m.\u001b[39mDataFrame(cosine_dist\u001b[38;5;241m.\u001b[39mloc[cosine_dist\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(cosine_dist_2\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]), names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      4\u001b[0m y1_y2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosine_dist_2' is not defined"
     ]
    }
   ],
   "source": [
    "y1_y2 = pd.DataFrame(np.array(cosine_dist_2[cosine_dist_2.loc[:,\"CIK\"].isin(cosine_dist.loc[:,\"CIK\"])].iloc[:,3:]) - \\\n",
    "    np.array(cosine_dist[cosine_dist.loc[:,\"CIK\"].isin(cosine_dist_2.loc[:,\"CIK\"])].iloc[:,3:]),\n",
    "                     index = pd.MultiIndex.from_frame(pd.DataFrame(cosine_dist.loc[cosine_dist.loc[:,\"CIK\"].isin(cosine_dist_2.loc[:,\"CIK\"]), \"CIK\"]), names=[\"CIK\"])).reset_index()\n",
    "y1_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8389e238-806f-435f-b614-0cb52d5fc625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1660134</td>\n",
       "      <td>OKTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1713683</td>\n",
       "      <td>Z-Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1065280</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51143</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40545</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIK      name\n",
       "0  1660134      OKTA\n",
       "1  1713683  Z-Scaler\n",
       "2  1065280      NFLX\n",
       "3    51143       IBM\n",
       "4    40545        GE"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32f2cb0d-b0c4-4a42-bb44-0fc214687bd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y1_y2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my1_y2\u001b[49m[y1_y2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(the_five[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m36\u001b[39m, axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y1_y2' is not defined"
     ]
    }
   ],
   "source": [
    "y1_y2[y1_y2[\"CIK\"].isin(the_five[\"CIK\"])].sort_values(by=36, axis =1, key = abs, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9005303-9e51-4551-91e0-6359abfa2740",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [w[:\u001b[38;5;241m300\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcluster_companies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "[w[:300] for w in cluster_companies[2].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f78fa756-2e39-47f8-8e6e-6af4e9a297ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_dist_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y2_y3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mcosine_dist_3\u001b[49m[cosine_dist_3\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(cosine_dist_2\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m:]) \u001b[38;5;241m-\u001b[39m \\\n\u001b[1;32m      2\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(cosine_dist_2[cosine_dist_2\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(cosine_dist_3\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m3\u001b[39m:]),\n\u001b[1;32m      3\u001b[0m                      index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_frame(pd\u001b[38;5;241m.\u001b[39mDataFrame(cosine_dist_2\u001b[38;5;241m.\u001b[39mloc[cosine_dist_2\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(cosine_dist_3\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]), names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      4\u001b[0m y2_y3\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cosine_dist_3' is not defined"
     ]
    }
   ],
   "source": [
    "y2_y3 = pd.DataFrame(np.array(cosine_dist_3[cosine_dist_3.loc[:,\"CIK\"].isin(cosine_dist_2.loc[:,\"CIK\"])].iloc[:,3:]) - \\\n",
    "    np.array(cosine_dist_2[cosine_dist_2.loc[:,\"CIK\"].isin(cosine_dist_3.loc[:,\"CIK\"])].iloc[:,3:]),\n",
    "                     index = pd.MultiIndex.from_frame(pd.DataFrame(cosine_dist_2.loc[cosine_dist_2.loc[:,\"CIK\"].isin(cosine_dist_3.loc[:,\"CIK\"]), \"CIK\"]), names=[\"CIK\"])).reset_index()\n",
    "y2_y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0026f6b6-8845-4635-b01d-25afb58e048e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y2_y3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my2_y3\u001b[49m[y2_y3[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(the_five[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y2_y3' is not defined"
     ]
    }
   ],
   "source": [
    "y2_y3[y2_y3[\"CIK\"].isin(the_five[\"CIK\"])].sort_values(by=32, axis =1, key = abs, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "522c2b30-544f-40be-a421-f89bc4c8b133",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m std_func\u001b[38;5;241m.\u001b[39mpca_visualize_2d(\u001b[43mdoc_vec\u001b[49m, pd\u001b[38;5;241m.\u001b[39mDataFrame(clustering\u001b[38;5;241m.\u001b[39mlabels_))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_vec' is not defined"
     ]
    }
   ],
   "source": [
    "std_func.pca_visualize_2d(doc_vec, pd.DataFrame(clustering.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50fe6bec-a279-4f0a-8883-d2abb6caef98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_w\u001b[49m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mmost_similar(positive \u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mibm\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_w' is not defined"
     ]
    }
   ],
   "source": [
    "model_w.wv.most_similar(positive =['ibm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25508ece-3c3a-4072-b215-d043bdc82cec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Since its not sparse, PCA should work just fine\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m multi_index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_frame(\u001b[43mfinal\u001b[49m\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilingDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      5\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "# Since its not sparse, PCA should work just fine\n",
    "multi_index = pd.MultiIndex.from_frame(final.loc[:,[\"filingDate\",\"CIK\", \"name\"]])\n",
    "    \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 10)\n",
    "pca_embedding = pca.fit_transform(doc_vec)\n",
    "pca_embedding = pd.DataFrame(pca_embedding, index = multi_index).reset_index()\n",
    "pca_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "691e571f-73da-45e6-af1e-8a84715a21a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_word2vec \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mfinal\u001b[49m\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilingDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]],doc_vec], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m delta_word2vec \u001b[38;5;241m=\u001b[39m deltas(final, data_word2vec, model_w\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mindex_to_key)\n\u001b[1;32m      3\u001b[0m delta_word2vec\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "data_word2vec = pd.concat([final.loc[:,[\"filingDate\",\"CIK\", \"name\"]],doc_vec], axis = 1)\n",
    "delta_word2vec = deltas(final, data_word2vec, model_w.wv.index_to_key)\n",
    "delta_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaef5485-d03c-4b7a-932c-1ada89c9f52e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_word2vec\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "data_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea3c9c81-d0ca-4a3c-999e-3a140ebc8c2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m analyzedDocument \u001b[38;5;241m=\u001b[39m namedtuple(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalyzedDocument\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords tags\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mfinal\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoDescription_stopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      7\u001b[0m     words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      8\u001b[0m     tags \u001b[38;5;241m=\u001b[39m [i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "\n",
    "docs = []\n",
    "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "for i, text in enumerate(final[\"coDescription_stopwords\"]):\n",
    "    words = text.lower().split()\n",
    "    tags = [i]\n",
    "    docs.append(analyzedDocument(words, tags))\n",
    "\n",
    "# Train model (set min_count = 1, if you want the model to work with the provided example data set)\n",
    "\n",
    "model = doc2vec.Doc2Vec(docs, vector_size = 100, window = 10, min_count = 1, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cf9defd-1d88-48ad-a16e-018a0cb0852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vec_2 = pd.DataFrame([model.dv[doc] for doc in np.arange(0,len(docs))])\n",
    "doc_vec_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25aae3fb-6759-4ad8-8d97-1e5fa3fee2b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m\n\u001b[1;32m      2\u001b[0m clusterer \u001b[38;5;241m=\u001b[39m hdbscan\u001b[38;5;241m.\u001b[39mHDBSCAN()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mclusterer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_vec_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/hdbscan/hdbscan_.py:1151\u001b[0m, in \u001b[0;36mHDBSCAN.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Perform HDBSCAN clustering from features or distance matrix.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;124;03m    Returns self\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# Non-precomputed matrices may contain non-finite values.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# Rows with these values\u001b[39;00m\n\u001b[0;32m-> 1151\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_finite \u001b[38;5;241m=\u001b[39m is_finite(X)\n",
      "File \u001b[0;32m~/Documents/GitHub/ubineer_nlp_research/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:665\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    662\u001b[0m                     has_pd_integer_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 665\u001b[0m         dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dtype_orig\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;66;03m# if input is object, convert to float.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "import hdbscan\n",
    "clusterer = hdbscan.HDBSCAN()\n",
    "clusterer.fit(doc_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7812f5b7-96ea-4a23-b19f-f81e9cafaaea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HDBSCAN' object has no attribute 'labels_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclusterer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_\u001b[49m\u001b[38;5;241m.\u001b[39mmax()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HDBSCAN' object has no attribute 'labels_'"
     ]
    }
   ],
   "source": [
    "clusterer.labels_.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
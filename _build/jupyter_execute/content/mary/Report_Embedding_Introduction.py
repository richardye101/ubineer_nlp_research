#!/usr/bin/env python
# coding: utf-8

# ## Document Embedding
# 
# The goal of this section is to find representations (embeddings) of company descriptions in a n-dimensional space that is able to cluster similar companies together, and separate dissimilar companies. 
# 
# We will implement the following techniques: 
# 1. [TF-IDF](https://richardye101.github.io/ubineer_nlp_research/content/richard/1_Tf-idf_analysis.html)
# 2. [Cosine Similarity] (https://richardye101.github.io/ubineer_nlp_research/content/peitong/1_Cosine_Similarity_Distances.html)
# 3. [Part-Of-Speech (POS) Tagging] (https://richardye101.github.io/ubineer_nlp_research/content/peitong/2_Part_of_Speech_Tagging.html)
# 4. [Word2Vec] (https://richardye101.github.io/ubineer_nlp_research/content/richard/4_Word2Vec.html)
# 5. [Doc2Vec] (https://richardye101.github.io/ubineer_nlp_research/content/richard/5_Doc2Vec.html)
# 6. [Two Towers] (https://richardye101.github.io/ubineer_nlp_research/content/mary/Report_TwoTowers.html)
# 7. [Universal Sentence Encoder] (https://richardye101.github.io/ubineer_nlp_research/content/mary/Report_USE.html)
# 
# At the end of this section, you can find a summary of the results for each of the techniques that we have used.

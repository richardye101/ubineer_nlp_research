{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maryx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maryx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maryx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maryx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maryx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maryx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'std_func' from 'C:\\\\Users\\\\maryx\\\\Desktop\\\\School\\\\Year 4\\\\STAD95\\\\report\\\\ubineer_nlp_research\\\\content\\\\mary\\\\..\\\\std_func.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import sys  \n",
    "sys.path.insert(0, '..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import std_func\n",
    "import importlib\n",
    "importlib.reload(std_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Topic Modelling\n",
    "Change is important for businesses to hold a competitive edge and to meet the ever-changing needs of customers. Netflix and General Electric are two examples of companies that have evolved to adapt to the fast moving trends of their respective industry. On the other hand, businesses like BlockBuster and MySpace failed to innovate and adapt with the moving trends. Investors often spend a great deal of time to read through finacial reports to detect signs of change and adaption, so our work systematically summarises the business model of a company over time. \n",
    "\n",
    "In this section, we apply several topic modelling techniques to the Business description of filings between the years of 2016 and 2018 to detect differences and emerging themes within a company. By finding these differences, we can see how the company has evolved over the years and understand shifts in operation of the company. More specifically, we explored Non-negative matrix factorization (NMF), latent dirichilet allocation (LDA), and Latent semantic analysis (LSA) for topic modelling.\n",
    "\n",
    "We use Netflix (NTFL) and General Electric (GE) as a Proof of Concept to test our topic models, since they are companies that have evolved drastically over the past 15 years.\n",
    "\n",
    "##### Netflix\n",
    "Netflix was founded by Reed Hastings and Marc Rudolph in 1997 as a DVD rental-by-mail business. A year later, Netflix introduced a subscription model where customers could rent DVDs online for a fixed fee per month. In 2007, it entered the market of video streaming where anyone could enjoy live streaming videos at their computer for for a monthly subscription fee. Around this time, the world was getting accustomed to the internet and technology was advancing rapidly. In 2009, the company began partnering with electronic companies to get Netflix on multiple devices like smart TVs and gaming consoles. This move attracted audiences with different background profiles and pushed Netflix to the top of the video-streaming industry. In 2011, Netflix introduced its mobile apps and ios service for smartphone users.\n",
    "\n",
    "Throughout the years, Netflix stayed competitive by changing their business strategy with the advancement of technology and catering to changing customer needs.\n",
    "\n",
    "##### General Electric\n",
    "General Electric (GE) was founded in 1892 and currently operates through eight industrial segments: Aviation, Healthcare, Transportation, Renewable Energy, Oil & Gas, Appliances & Lighting, Power & Water,and Capital. GE Aviation is GE's most profitable division. It made steps forward in recent years, namely 2007 by acquiring Smith Aerospace, an American aircraft engine and aircraft parts manufacturer, and 2012 by acquiring Avio S.p.A., an Italy-based manufacturer of aviation propulsion components and systems for civil and military aircraft. On the other hand, GE Healthcare had slow growth in the years of 2010 to 2015 but saw an significant increase in profits in 2016 by more than 0.3 billion dollars compared to the year before. GE Power & Water, GE Renewable Energy, GE Oil & Gas were all under GE Energy up until its split in 2012. In 2014, GE's Power made moves to purchase French gas turbine company Alstom for $\\$$ 13 billion dollars. Unfortunately, this move coincided with a global downturn in the price of renewables, lessening demand for the gas turbines, and did not bring the profits that GE had hoped for. 2014 was also the year that GE agreed to sell GE Appliances to Electrolux, a Swedish appliance manufacturer and the second-largest consumer appliance manufacturer after Whirlpool Corporation, for US $\\$$3.3 billion in cash.\n",
    "\n",
    "In the history of the business, GE suffered through the financial crisis in 2008 and began its downfall. Throughout 2008 to 2017, the company consistently slashed its dividends year over year and laid off thousands of employees across all divisions. However, in 2018, GE made significant improvements in cutting debt and raising capital by selling off subsidiaries. In 2021, GE decided to separate GE HealthCare and GE Power into public companies and focus mainly on GE Aviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dynamic Topic Modelling with Netflix, GE\n",
    "targetComp = pd.read_csv(\"../data/dynamic_companies.csv\")\n",
    "netflix = targetComp[targetComp[\"financialEntity\"] == \"financialEntities/params;cik=1065280\"].sort_values([\"filingDate\"])\n",
    "ge = targetComp[targetComp[\"financialEntity\"] == \"financialEntities/params;cik=40545\"].sort_values([\"filingDate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-Negative Matrix Factorization\n",
    "Non-negative matrix factorization uses linear algebra to discover underlying relationships between texts. It factorizes/decomposes high-dimensionality vectors(ie. TF-IDF or BOW embeddings) into a lower dimensional representation. Given an original matrix obtained using TF-IDF or any word embedding algorithm of size MxN where M is the number of documents and N is the number of ngrams, NMF generates the **Feature** matrix and **Components** matrix. The Features matrix represents weights of topics for each doument and Component matrix represents weights of words for each topic. NMF modifies the values of the initial Feature matrix and Components matrix so that the product approaches the original matrix until approximation error converges or max iterations are reached (ie. $Original Matrix \\approx$ $Features \\times Components$) . The matrices generated by NMF will only give non-negative values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF is very sensitive to the hyperparameters such as the number of topics, so we can use coherence scores to evaluate the most optimal number of topics so that each topic is human interpretable.The coherence of a topic, used as a proxy for topic quality, is based on the distributional hypothesis that states that words with similar meaning tend to co-occur within a similar context.\n",
    "\n",
    "Coherence score measures the relative distance between words within a topic. There are several coherence metrics but the most popular one is CV, which is the metrics that we will use in our report. CV coherence score creates content vectors of words using their co-occurrences (ie. co-occurence of \"Las\" and \"Vegas\" would be very high) and calculates the score using normalized pointwise mutual information (NPMI) and cosine similarity. NPMI is the likelihood of the co-occurrence of two words, taking into account the fact that it might be caused by the frequency of the single words. \n",
    "\n",
    "$NPMI(a,b) = \\frac{log\\frac{P(a,b)+\\epsilon}{P(a)P(b)}}{-log(P(a,b)+\\epsilon)}$\n",
    "\n",
    "Probabilities of single words p(a) or the joint probabilizy of two words p(a,b) can be estimated by Boolean document calculation, that is, the number of documents in which (a) or (a,b) occurs, divided by the total number of documents.\n",
    "\n",
    "We calculate the global coherence of the topic as the average pairwise coherence scores on the top N words which describe the topic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the metric over a range of 3 to 40 topics, incrementing by 3 and achieved the result below. Although coherence is highest for 6 topics, we know that there are close to 50 different categories of companies in the dataset and thus 6 topics will not give well separated results. Therefore, we chose the give our model 18 topics, which has the next highest coherence score and will not give topics that are too specific to this set of data. If you're interested in the code, see this  [file](https://richardye101.github.io/ubineer_nlp_research/lab?path=mary%2FWeek+10+-+NMF+vs+LDA+vs+LSA.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NMF Coherence](../images/nmf_coherence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below illustrates the results produced by the NMF model tuned to generate 18 topics. Each column is a topic identified by the column index and is represented by the top 10 words in the topic by weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maryx\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "      <th>Topic # 09</th>\n",
       "      <th>Topic # 10</th>\n",
       "      <th>Topic # 11</th>\n",
       "      <th>Topic # 12</th>\n",
       "      <th>Topic # 13</th>\n",
       "      <th>Topic # 14</th>\n",
       "      <th>Topic # 15</th>\n",
       "      <th>Topic # 16</th>\n",
       "      <th>Topic # 17</th>\n",
       "      <th>Topic # 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customer</td>\n",
       "      <td>store</td>\n",
       "      <td>share</td>\n",
       "      <td>patient</td>\n",
       "      <td>loan</td>\n",
       "      <td>gas</td>\n",
       "      <td>ethanol</td>\n",
       "      <td>software</td>\n",
       "      <td>president</td>\n",
       "      <td>tax</td>\n",
       "      <td>brand</td>\n",
       "      <td>mineral</td>\n",
       "      <td>investment</td>\n",
       "      <td>cannabis</td>\n",
       "      <td>home</td>\n",
       "      <td>item</td>\n",
       "      <td>client</td>\n",
       "      <td>aircraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manufacturing</td>\n",
       "      <td>merchandise</td>\n",
       "      <td>stock</td>\n",
       "      <td>clinical</td>\n",
       "      <td>bank</td>\n",
       "      <td>oil</td>\n",
       "      <td>corn</td>\n",
       "      <td>customer</td>\n",
       "      <td>vice</td>\n",
       "      <td>income</td>\n",
       "      <td>food</td>\n",
       "      <td>exploration</td>\n",
       "      <td>fund</td>\n",
       "      <td>medical</td>\n",
       "      <td>land</td>\n",
       "      <td>statement</td>\n",
       "      <td>solution</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>material</td>\n",
       "      <td>customer</td>\n",
       "      <td>common</td>\n",
       "      <td>fda</td>\n",
       "      <td>credit</td>\n",
       "      <td>natural</td>\n",
       "      <td>grain</td>\n",
       "      <td>application</td>\n",
       "      <td>officer</td>\n",
       "      <td>cash</td>\n",
       "      <td>consumer</td>\n",
       "      <td>mining</td>\n",
       "      <td>adviser</td>\n",
       "      <td>lease</td>\n",
       "      <td>property</td>\n",
       "      <td>registrant</td>\n",
       "      <td>care</td>\n",
       "      <td>aviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semiconductor</td>\n",
       "      <td>brand</td>\n",
       "      <td>agreement</td>\n",
       "      <td>trial</td>\n",
       "      <td>institution</td>\n",
       "      <td>drilling</td>\n",
       "      <td>distiller</td>\n",
       "      <td>solution</td>\n",
       "      <td>chief</td>\n",
       "      <td>asset</td>\n",
       "      <td>segment</td>\n",
       "      <td>claim</td>\n",
       "      <td>portfolio</td>\n",
       "      <td>property</td>\n",
       "      <td>construction</td>\n",
       "      <td>part</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>technology</td>\n",
       "      <td>apparel</td>\n",
       "      <td>merger</td>\n",
       "      <td>drug</td>\n",
       "      <td>borrower</td>\n",
       "      <td>well</td>\n",
       "      <td>fuel</td>\n",
       "      <td>data</td>\n",
       "      <td>served</td>\n",
       "      <td>note</td>\n",
       "      <td>retail</td>\n",
       "      <td>gold</td>\n",
       "      <td>income</td>\n",
       "      <td>colorado</td>\n",
       "      <td>community</td>\n",
       "      <td>stockholder</td>\n",
       "      <td>health</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>equipment</td>\n",
       "      <td>retail</td>\n",
       "      <td>shareholder</td>\n",
       "      <td>cancer</td>\n",
       "      <td>mortgage</td>\n",
       "      <td>pipeline</td>\n",
       "      <td>gallon</td>\n",
       "      <td>platform</td>\n",
       "      <td>executive</td>\n",
       "      <td>net</td>\n",
       "      <td>beverage</td>\n",
       "      <td>property</td>\n",
       "      <td>capital</td>\n",
       "      <td>pharmaceutical</td>\n",
       "      <td>mortgage</td>\n",
       "      <td>equity</td>\n",
       "      <td>provider</td>\n",
       "      <td>military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>industrial</td>\n",
       "      <td>fiscal</td>\n",
       "      <td>director</td>\n",
       "      <td>device</td>\n",
       "      <td>deposit</td>\n",
       "      <td>production</td>\n",
       "      <td>plant</td>\n",
       "      <td>user</td>\n",
       "      <td>senior</td>\n",
       "      <td>loss</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>project</td>\n",
       "      <td>advisor</td>\n",
       "      <td>facility</td>\n",
       "      <td>estate</td>\n",
       "      <td>supplementary</td>\n",
       "      <td>provide</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>segment</td>\n",
       "      <td>assortment</td>\n",
       "      <td>issued</td>\n",
       "      <td>treatment</td>\n",
       "      <td>lending</td>\n",
       "      <td>reserve</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>cloud</td>\n",
       "      <td>since</td>\n",
       "      <td>liability</td>\n",
       "      <td>agreement</td>\n",
       "      <td>mine</td>\n",
       "      <td>security</td>\n",
       "      <td>growing</td>\n",
       "      <td>real</td>\n",
       "      <td>discussion</td>\n",
       "      <td>segment</td>\n",
       "      <td>engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>system</td>\n",
       "      <td>retailer</td>\n",
       "      <td>outstanding</td>\n",
       "      <td>study</td>\n",
       "      <td>federal</td>\n",
       "      <td>crude</td>\n",
       "      <td>renewable</td>\n",
       "      <td>network</td>\n",
       "      <td>director</td>\n",
       "      <td>statement</td>\n",
       "      <td>ingredient</td>\n",
       "      <td>permit</td>\n",
       "      <td>fee</td>\n",
       "      <td>plant</td>\n",
       "      <td>building</td>\n",
       "      <td>disclosure</td>\n",
       "      <td>revenue</td>\n",
       "      <td>defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>solution</td>\n",
       "      <td>footwear</td>\n",
       "      <td>exchange</td>\n",
       "      <td>therapy</td>\n",
       "      <td>estate</td>\n",
       "      <td>water</td>\n",
       "      <td>energy</td>\n",
       "      <td>mobile</td>\n",
       "      <td>joining</td>\n",
       "      <td>ended</td>\n",
       "      <td>distribution</td>\n",
       "      <td>environmental</td>\n",
       "      <td>equity</td>\n",
       "      <td>warrant</td>\n",
       "      <td>residential</td>\n",
       "      <td>ii</td>\n",
       "      <td>security</td>\n",
       "      <td>contract</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic # 01   Topic # 02   Topic # 03 Topic # 04   Topic # 05  \\\n",
       "0       customer        store        share    patient         loan   \n",
       "1  manufacturing  merchandise        stock   clinical         bank   \n",
       "2       material     customer       common        fda       credit   \n",
       "3  semiconductor        brand    agreement      trial  institution   \n",
       "4     technology      apparel       merger       drug     borrower   \n",
       "5      equipment       retail  shareholder     cancer     mortgage   \n",
       "6     industrial       fiscal     director     device      deposit   \n",
       "7        segment   assortment       issued  treatment      lending   \n",
       "8         system     retailer  outstanding      study      federal   \n",
       "9       solution     footwear     exchange    therapy       estate   \n",
       "\n",
       "   Topic # 06 Topic # 07   Topic # 08 Topic # 09 Topic # 10    Topic # 11  \\\n",
       "0         gas    ethanol     software  president        tax         brand   \n",
       "1         oil       corn     customer       vice     income          food   \n",
       "2     natural      grain  application    officer       cash      consumer   \n",
       "3    drilling  distiller     solution      chief      asset       segment   \n",
       "4        well       fuel         data     served       note        retail   \n",
       "5    pipeline     gallon     platform  executive        net      beverage   \n",
       "6  production      plant         user     senior       loss    restaurant   \n",
       "7     reserve   gasoline        cloud      since  liability     agreement   \n",
       "8       crude  renewable      network   director  statement    ingredient   \n",
       "9       water     energy       mobile    joining      ended  distribution   \n",
       "\n",
       "      Topic # 12  Topic # 13      Topic # 14    Topic # 15     Topic # 16  \\\n",
       "0        mineral  investment        cannabis          home           item   \n",
       "1    exploration        fund         medical          land      statement   \n",
       "2         mining     adviser           lease      property     registrant   \n",
       "3          claim   portfolio        property  construction           part   \n",
       "4           gold      income        colorado     community    stockholder   \n",
       "5       property     capital  pharmaceutical      mortgage         equity   \n",
       "6        project     advisor        facility        estate  supplementary   \n",
       "7           mine    security         growing          real     discussion   \n",
       "8         permit         fee           plant      building     disclosure   \n",
       "9  environmental      equity         warrant   residential             ii   \n",
       "\n",
       "   Topic # 17 Topic # 18  \n",
       "0      client   aircraft  \n",
       "1    solution     system  \n",
       "2        care   aviation  \n",
       "3  healthcare     flight  \n",
       "4      health      power  \n",
       "5    provider   military  \n",
       "6     provide     energy  \n",
       "7     segment     engine  \n",
       "8     revenue    defense  \n",
       "9    security   contract  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "filtered = pd.read_csv(\"filtered_timeseries_data.csv\")\n",
    "filtered_data = filtered.loc[:,\"coDescription_stopwords\"].to_list()\n",
    "filtered_dates = filtered[\"filingDate\"].to_list()\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.85, max_features=2000) \n",
    "filtered_all_X = tf_vectorizer.fit_transform(filtered_data)\n",
    "\n",
    "nmf_model = NMF(n_components=18, init='nndsvd', random_state=0)\n",
    "nmf_feature = nmf_model.fit_transform(filtered_all_X)\n",
    "nmf_component =nmf_model.components_\n",
    "\n",
    "nmf_topics = std_func.get_topics(nmf_model,tf_vectorizer, 18)\n",
    "nmf_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Netflix Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting decrease in Topic 8 (software) especially in 2011 when Netflix rolled out mobile apps for smartphone users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_X = tf_vectorizer.transform(netflix[\"coDescription\"].tolist())\n",
    "netflix_top = nmf_model.transform(netflix_X)\n",
    "netflix_top_df = pd.DataFrame(netflix_top).set_index(netflix[\"filingDate\"])\n",
    "# netflix_top_df.columns = [\"Topic #\" + str(i) for i in range(1,18+)]1\n",
    "std_func.graph_netflix(18, netflix_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "#compare 2012 with 2008 \n",
    "std_func.get_differences(nmf_topics, netflix_top_df.iloc[-1], netflix_top_df.iloc[0]).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decrease in topic 2(retail/store), 15(real estate/residential)\n",
    "- increase in topic 10 (finances), 11 (food), 16(common financial report terms)\n",
    "\n",
    "Anlysis: \n",
    "\n",
    "Decrease in topic 2(retail/store) and 15(real estate/residential) may be a result of Netflix's change in business model in 2007 which hugely emphasized moving into the video streaming industry and being able to watch content in the comfort of your own home. However, in 2014, the business model is already established so there is a decrease on the emphasis of these topics. \n",
    "\n",
    "Topics 11,16, 10 are too general to be interpreted or is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### General Electric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_X = tf_vectorizer.transform(ge[\"coDescription\"].tolist())\n",
    "ge_top = nmf_model.transform(ge_X)\n",
    "ge_top_df = pd.DataFrame(ge_top).set_index(ge[\"filingDate\"])\n",
    "std_func.graph_ge(18, ge_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #compare 2014 to 2011 \n",
    "std_func.get_differences(nmf_topics, ge_top_df.iloc[-1], ge_top_df.iloc[0]).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decrease in topic 15(real estate/land), 18(aerospace, vehicles)\n",
    "- increase in topic 5(loan/bank), 6(energy/gas), 16 (financial/analysis)\n",
    "\n",
    "Anlysis: \n",
    "\n",
    "Decrease in topic 18(aerospace/vehicles) may indicate that the company is seeing steady growth in the Aerospace section and did not make major changes in their business model. Decrease in topic 15(real estate/residential) may be explained by the planned acquisition of GE Appliances by Electrolux. \n",
    "\n",
    "Increase in Topic 5 (loan/bank) may be explained by its acquistion activities where GE Power acquired Alcom and GE Appliances is set to be acquired by Electrolux. Increase in Topic 6(energy/gas) may be explained by GE Power's plan to acquire Alcom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult to interpret the topics, there are several different categories of words in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "svd_model = pd.DataFrame(svd.fit_transform(filtered_all_X))\n",
    "lsa_topics = std_func.get_topics(svd,tf_vectorizer, 20)\n",
    "lsa_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "###### Netflix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_top = svd.transform(netflix_X)\n",
    "netflix_top_df = pd.DataFrame(netflix_top).set_index(netflix[\"filingDate\"])\n",
    "std_func.graph_netflix(20, netflix_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare 2012 with 2008 \n",
    "std_func.get_differences(lsa_topics,netflix_top_df.iloc[-1], netflix_top_df.iloc[0]).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decrease in topic 2(retail/store) ,8(software, mining), 10(loan, home, commodities, cannabis), 13(investment, cannabis)\n",
    "- increase in topic 17(mining, financial)\n",
    "\n",
    "Anlysis: \n",
    "\n",
    "Decrease in topic 2(retail/store) and 8(software, mining) may be a result of Netflix's change in business model in 2007 which hugely emphasized moving into the video streaming industry and being able to watch content in the comfort of your own home. However, in 2014, the business model is already established so there is a decrease on the emphasis of these topics.\n",
    "\n",
    "Topics 10, 13, 17 are too general to be interpreted, or is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### General Electric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_top = svd.transform(ge_X)\n",
    "ge_top_df = pd.DataFrame(ge_top).set_index(ge[\"filingDate\"])\n",
    "std_func.graph_ge(20, ge_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare 2014 to 2011 \n",
    "std_func.get_differences(lsa_topics,ge_top_df.iloc[-1],ge_top_df.iloc[0]).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decrease in topic 18(aerospace)\n",
    "- increase in topic 14(business, acquisition), 17(mining, financial), 19(food/store), 20(vehicle, mineral, partner)\n",
    "\n",
    "Anlysis: \n",
    "\n",
    "Decrease in topic 18(aerospace/vehicles) may indicate that the company is seeing steady growth in the Aerospace section and did not make major changes in their business model. \n",
    "\n",
    "Increase in Topic 14(business, acquisition) may be explained by its increased acquistion activities where GE Power acquired Alcom and GE Appliances is set to be acquired by Electrolux.\n",
    "\n",
    "Topic 17, 19, 20 are too general to be interpreted or is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the coherence score benchmarking over a range of 3 to 40 topics, incrementing by 3 and achieved the result below. We chose the give our model 9 topics, which has the highest coherence score. If you're interested in the code, see this  [file](https://richardye101.github.io/ubineer_nlp_research/lab?path=mary%2FWeek+10+-+NMF+vs+LDA+vs+LSA.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NMF Coherence](../images/lda_coherence.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "count_vectorizer = CountVectorizer(max_df=0.85, min_df=2, max_features=2000)\n",
    "filtered_all_count_X = count_vectorizer.fit_transform(filtered_data)\n",
    "count_feature_names = count_vectorizer.get_feature_names()\n",
    "lda = LatentDirichletAllocation(n_components=9,random_state=0).fit(filtered_all_count_X)\n",
    "lda_topics = std_func.get_topics(lda,count_vectorizer, 9)\n",
    "lda_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Netflix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "netlfix_X = count_vectorizer.transform(netflix[\"coDescription\"].tolist())\n",
    "netflix_top = lda.transform(netlfix_X)\n",
    "netflix_top_df = pd.DataFrame(netflix_top).set_index(netflix[\"filingDate\"])\n",
    "std_func.graph_netflix(9, netflix_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare 2012 with 2008 \n",
    "std_func.get_differences(lda_topics,netflix_top_df.iloc[-1], netflix_top_df.iloc[0]).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decrease in topic 1(common financial terms) ,5(software)\n",
    "- increase in topic 6(common financial terms), 7(retail/branding), 9(managment positions?)\n",
    "\n",
    "Anlysis: \n",
    "\n",
    "Decrease in topic 5 (software) may be a result of Netflix's change in business model in 2007 which hugely emphasized moving into the video streaming/software industry. However, in 2014, the business model is already established so there is a decrease on the emphasis of software.\n",
    "\n",
    "Topics 1,6,7,9 are too general to be interpreted or is irrelevant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### General Electric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_X =  count_vectorizer.transform(ge[\"coDescription\"].tolist())\n",
    "ge_top = lda.transform(ge_X )\n",
    "ge_top_df = pd.DataFrame(ge_top).set_index(ge[\"filingDate\"])\n",
    "std_func.graph_ge(9, ge_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare 2014 to 2011 \n",
    "std_func.get_differences(lda_topics,ge_top_df.iloc[-1],ge_top_df.iloc[0]).iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decrease in topic 9(managment positions?)\n",
    "- increase in topic 7(retail/branding), 8(finance, loan), 1(common financial report terms), 6(positive financial report terms)\n",
    "\n",
    "Anlysis: \n",
    "Topics are too general to be interpreted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary of Topic Modelling\n",
    "##### NMF Results\n",
    "__Netflix__\n",
    "- decrease in topic 2(retail/store), 15(real estate/residential)\n",
    "- increase in topic 10 (finances), 11 (food), 16(common financial report terms)\n",
    "\n",
    "__GE__\n",
    "- decrease in topic 15(real estate/land), 18(aerospace, vehicles)\n",
    "- increase in topic 5(loan/bank), 6(energy/gas), 16 (financial/analysis)\n",
    "\n",
    "##### LDA Results\n",
    "\n",
    "__Netflix__\n",
    "- decrease in topic 1(common financial terms) ,5(software)\n",
    "- increase in topic 6(common financial terms), 7(retail/branding), 9(managment positions?)\n",
    "\n",
    "__GE__\n",
    "- decrease in topic 9(managment positions?)\n",
    "- increase in topic 7(retail/branding), 8(finance, loan), 1(common financial report terms), 6(positive financial report terms)\n",
    "\n",
    "##### LSA Results\n",
    "\n",
    "__Netflix__\n",
    "- decrease in topic 2(retail/store) ,8(software, mining), 10(loan, home, commodities, cannabis), 13(investment, cannabis)\n",
    "- increase in topic 17(mining, financial)\n",
    "\n",
    "__GE__\n",
    "- decrease in topic 18(aerospace)\n",
    "- increase in topic 14(business, acquisition), 17(mining, financial), 19(food/store), 20(vehicle, mineral, partner)\n",
    "\n",
    "\n",
    "\n",
    "Topics generated by the NMF model is the easiest to evaluate and is more coherent compared to LDA and LSA. We saw that the LSA model generated topics with mixed category of words in each topic and contained negative weights which is difficult to interpret.  The LDA model generated many topics with common financial terms that appear in most 10k reports so it did not give meaningful information of each company. Therefore, NMF does the best using this dataset which is expected since NMF usually has higher performance than LDA and LSA when using a small dataset.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a47689b",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder\n",
    "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. It is trained on a variety of data sources to learn for a wide variety of tasks. The sources are Wikipedia, web news, web question-answer pages, and discussion forums. The input is a variable-length English text and the output is a 512-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7cad51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed07e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('bq_2018_top5SIC.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d604ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['reportingDate', 'name', 'coDescription', 'SIC', 'SIC_desc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde284fb",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "#### - Normalization\n",
    "#### - Remove Stopwords\n",
    "#### - Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f641106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reportingDate</th>\n",
       "      <th>name</th>\n",
       "      <th>coDescription</th>\n",
       "      <th>SIC</th>\n",
       "      <th>SIC_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>MONGODB, INC.</td>\n",
       "      <td>overviewmongodb is the leading modern general ...</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>SALESFORCE COM INC</td>\n",
       "      <td>overviewsalesforce is a global leader in custo...</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>SPLUNK INC</td>\n",
       "      <td>overviewsplunk provides innovative software so...</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>OKTA, INC.</td>\n",
       "      <td>overview okta is the leading independent provi...</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>VEEVA SYSTEMS INC</td>\n",
       "      <td>overview veeva is a leading provider of indust...</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AMERICAN REALTY CAPITAL NEW YORK CITY REIT, INC.</td>\n",
       "      <td>organizationwe were incorporated on december  ...</td>\n",
       "      <td>6798</td>\n",
       "      <td>Real Estate Investment Trusts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>CYCLACEL PHARMACEUTICALS, INC.</td>\n",
       "      <td>the following business section contains forwar...</td>\n",
       "      <td>2834</td>\n",
       "      <td>Pharmaceutical Preparations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>ZOETIS INC.</td>\n",
       "      <td>productscosts and expenses costs of sales cons...</td>\n",
       "      <td>2834</td>\n",
       "      <td>Pharmaceutical Preparations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>STAG INDUSTRIAL, INC.</td>\n",
       "      <td>certain definitionsin this reportwe define gaa...</td>\n",
       "      <td>6798</td>\n",
       "      <td>Real Estate Investment Trusts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>EQUINIX INC</td>\n",
       "      <td>the words equinix we our ours us and the compa...</td>\n",
       "      <td>6798</td>\n",
       "      <td>Real Estate Investment Trusts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    reportingDate                                              name  \\\n",
       "0      2018-02-01                                     MONGODB, INC.   \n",
       "1      2018-02-01                                SALESFORCE COM INC   \n",
       "2      2018-02-01                                        SPLUNK INC   \n",
       "3      2018-02-01                                        OKTA, INC.   \n",
       "4      2018-02-01                                 VEEVA SYSTEMS INC   \n",
       "..            ...                                               ...   \n",
       "668    2019-01-01  AMERICAN REALTY CAPITAL NEW YORK CITY REIT, INC.   \n",
       "669    2019-01-01                    CYCLACEL PHARMACEUTICALS, INC.   \n",
       "670    2019-01-01                                       ZOETIS INC.   \n",
       "671    2019-01-01                             STAG INDUSTRIAL, INC.   \n",
       "672    2019-01-01                                       EQUINIX INC   \n",
       "\n",
       "                                         coDescription   SIC  \\\n",
       "0    overviewmongodb is the leading modern general ...  7372   \n",
       "1    overviewsalesforce is a global leader in custo...  7372   \n",
       "2    overviewsplunk provides innovative software so...  7372   \n",
       "3    overview okta is the leading independent provi...  7372   \n",
       "4    overview veeva is a leading provider of indust...  7372   \n",
       "..                                                 ...   ...   \n",
       "668  organizationwe were incorporated on december  ...  6798   \n",
       "669  the following business section contains forwar...  2834   \n",
       "670  productscosts and expenses costs of sales cons...  2834   \n",
       "671  certain definitionsin this reportwe define gaa...  6798   \n",
       "672  the words equinix we our ours us and the compa...  6798   \n",
       "\n",
       "                                              SIC_desc  \n",
       "0    Prepackaged Software (mass reproduction of sof...  \n",
       "1    Prepackaged Software (mass reproduction of sof...  \n",
       "2    Prepackaged Software (mass reproduction of sof...  \n",
       "3    Prepackaged Software (mass reproduction of sof...  \n",
       "4    Prepackaged Software (mass reproduction of sof...  \n",
       "..                                                 ...  \n",
       "668                      Real Estate Investment Trusts  \n",
       "669                        Pharmaceutical Preparations  \n",
       "670                        Pharmaceutical Preparations  \n",
       "671                      Real Estate Investment Trusts  \n",
       "672                      Real Estate Investment Trusts  \n",
       "\n",
       "[673 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#strip any left over html code\n",
    "def clean_data_fn(insrt_data):\n",
    "    \n",
    "    clean_data = []\n",
    "    \n",
    "    for idx, ele in insrt_data.iterrows():\n",
    "        if \"https://www.sec.gov/Archives/edgar/data/\" in ele[2]:\n",
    "            pass\n",
    "        else:\n",
    "            clean_txt = re.compile('<.*?>')\n",
    "            \n",
    "            pos = 0\n",
    "            \n",
    "            desc = re.sub(clean_txt,'',ele[\"coDescription\"]).replace(u'\\xa0', u' ').replace(\"   \", \"\").replace(\"'\", \"\").replace('\"','')\n",
    "            \n",
    "            desc = desc.lower()\n",
    "            \n",
    "            if re.search('<', desc):\n",
    "                pos = re.search('<', desc).start()\n",
    "            \n",
    "            desc = desc[:pos]\n",
    "            \n",
    "            if (desc.find(\"business\") == -1): # didnt find it then look for next\n",
    "                if(desc.find(\"business.\") == -1): # didnt find it then just remove anything after \"<\" if at all\n",
    "                    desc = desc[6 : ( desc.rfind(\"<\") )]\n",
    "\n",
    "                else: # found \"Business.\", remove everything before it\n",
    "                    desc =  desc[( desc.find(\"business.\") + 9 ) : ( desc.rfind(\"<\") ) ]\n",
    "            else:\n",
    "                desc = desc[( desc.find(\"business\") + 8 ) : ( desc.rfind(\"<\") ) ]\n",
    "            \n",
    "            # remove leading white space and punctuation\n",
    "            desc = re.sub(r'[\\.\\?\\!\\,\\:\\;\\\"]', '', desc).strip()\n",
    "            \n",
    "            # remove the non-letters\n",
    "            desc = ''.join([x for x in desc if x in string.ascii_letters + '\\'- '])\n",
    "                \n",
    "            new_data = pd.Series([ele[0], ele[1], desc, ele[3], ele[4]], index = insrt_data.columns)\n",
    "            \n",
    "            if len(desc)<250:\n",
    "                pass\n",
    "            else:\n",
    "                clean_data.append(new_data)\n",
    "    return(pd.DataFrame(clean_data))\n",
    "\n",
    "df = clean_data_fn(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f230f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "## Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def removeStopWords(description):\n",
    "    text_tokens = word_tokenize(description)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    print(\"in\")\n",
    "    return (\" \").join(tokens_without_sw)\n",
    "\n",
    "df[\"coDescription\"] = df[\"coDescription\"].apply(removeStopWords)\n",
    "df[\"coDescription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a04042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def nltk2wn_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:                    \n",
    "        return None\n",
    "    \n",
    "def lemmatize_sentence(sentence):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))    \n",
    "    wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
    "    res_words = []\n",
    "    for word, tag in wn_tagged:\n",
    "        if tag is None:                        \n",
    "            res_words.append(word)\n",
    "        else:\n",
    "            res_words.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(res_words)\n",
    "\n",
    "lemma_desc = df[\"coDescription\"].apply(lemmatize_sentence)\n",
    "df[\"coDescription_lemmatized\"] = lemma_desc\n",
    "df[\"coDescription_lemmatized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a540255",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e54a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "!pip3 install seaborn\n",
    "import seaborn as sns\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(df[\"coDescription_lemmatized\"])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a840a",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "      corr,\n",
    "      xticklabels=labels,\n",
    "      yticklabels=labels,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "plot_similarity(df[\"name\"][:20],embeddings[:20], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece38133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "\n",
    "# Referenced from my CSCD25 course\n",
    "def visualize_pca(vectors, index):\n",
    "    multi_index = pd.MultiIndex.from_frame(index, names=[\"name\", \"industry\"])\n",
    "    \n",
    "    pca = PCA(n_components = 50)\n",
    "    pca_embedding = pca.fit_transform(vectors)\n",
    "    pca_embedding = pd.DataFrame(pca_embedding, index = multi_index)\n",
    "    \n",
    "    fig = px.scatter(pca_embedding, x =0 , y = 1, hover_data={\"name\": pca_embedding.index.get_level_values(0),\n",
    "                                                              \"industry\": pca_embedding.index.get_level_values(1)},\n",
    "                     color = pca_embedding.index.get_level_values(1), width=1200, height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    return [pca, pca_embedding]\n",
    "\n",
    "plot_pca = visualize_pca(embeddings, df.loc[:,[\"name\",\"SIC_desc\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(plot_pca[1], x =0 , y = 1, z = 2, hover_data={\"name\": plot_pca[1].index.get_level_values(0),\n",
    "                                                              \"industry\": plot_pca[1].index.get_level_values(1)},\n",
    "                    color = plot_pca[1].index.get_level_values(1), width=1200, height=700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    \n",
    "corr = np.inner(embeddings, embeddings)\n",
    "len(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = pd.DataFrame(embeddings)\n",
    "embedding_matrix.index = df[\"name\"]\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b09109",
   "metadata": {},
   "source": [
    "## Similarity Matrix\n",
    "USE gives normalized embeddings, so the inner product of encodings can be treated as a similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = np.matmul(embedding_matrix, embedding_matrix.T)\n",
    "np.fill_diagonal(dot_product.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f554303",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product.index = df[\"SIC_desc\"]\n",
    "dot_product.columns = df[\"SIC_desc\"]\n",
    "dot_product_df = pd.DataFrame(dot_product.idxmax(axis=1))\n",
    "dot_product_df.reset_index(level=0, inplace=True)\n",
    "dot_product_df.columns = [\"desc1\",\"desc2\"]\n",
    "dot_product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of correct category predictions: \")\n",
    "print(np.sum(np.where(dot_product_df.iloc[:,1] == dot_product_df.iloc[:,0], 1, 0))/len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c57565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

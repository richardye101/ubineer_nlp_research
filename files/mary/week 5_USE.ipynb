{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a47689b",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder\n",
    "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. It is trained on a variety of data sources to learn for a wide variety of tasks. The sources are Wikipedia, web news, web question-answer pages, and discussion forums. The input is a variable-length English text and the output is a 512-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7cad51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed07e7ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbq_2018_top5SIC.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:612\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:744\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m         data \u001b[38;5;241m=\u001b[39m ensure_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m    743\u001b[0m         data_lines \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 744\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    746\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:768\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    766\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 768\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:880\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 880\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:1133\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1133\u001b[0m         \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m     )\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1136\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1139\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('bq_2018_top5SIC.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d604ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['reportingDate', 'name', 'coDescription', 'SIC', 'SIC_desc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde284fb",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "#### - Normalization\n",
    "#### - Remove Stopwords\n",
    "#### - Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f641106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip any left over html code\n",
    "def clean_data_fn(insrt_data):\n",
    "    \n",
    "    clean_data = []\n",
    "    \n",
    "    for idx, ele in insrt_data.iterrows():\n",
    "        if \"https://www.sec.gov/Archives/edgar/data/\" in ele[2]:\n",
    "            pass\n",
    "        else:\n",
    "            clean_txt = re.compile('<.*?>')\n",
    "            \n",
    "            pos = 0\n",
    "            \n",
    "            desc = re.sub(clean_txt,'',ele[\"coDescription\"]).replace(u'\\xa0', u' ').replace(\"   \", \"\").replace(\"'\", \"\").replace('\"','')\n",
    "            \n",
    "            desc = desc.lower()\n",
    "            \n",
    "            if re.search('<', desc):\n",
    "                pos = re.search('<', desc).start()\n",
    "            \n",
    "            desc = desc[:pos]\n",
    "            \n",
    "            if (desc.find(\"business\") == -1): # didnt find it then look for next\n",
    "                if(desc.find(\"business.\") == -1): # didnt find it then just remove anything after \"<\" if at all\n",
    "                    desc = desc[6 : ( desc.rfind(\"<\") )]\n",
    "\n",
    "                else: # found \"Business.\", remove everything before it\n",
    "                    desc =  desc[( desc.find(\"business.\") + 9 ) : ( desc.rfind(\"<\") ) ]\n",
    "            else:\n",
    "                desc = desc[( desc.find(\"business\") + 8 ) : ( desc.rfind(\"<\") ) ]\n",
    "            \n",
    "            # remove leading white space and punctuation\n",
    "            desc = re.sub(r'[\\.\\?\\!\\,\\:\\;\\\"]', '', desc).strip()\n",
    "            \n",
    "            # remove the non-letters\n",
    "            desc = ''.join([x for x in desc if x in string.ascii_letters + '\\'- '])\n",
    "                \n",
    "            new_data = pd.Series([ele[0], ele[1], desc, ele[3], ele[4]], index = insrt_data.columns)\n",
    "            \n",
    "            if len(desc)<250:\n",
    "                pass\n",
    "            else:\n",
    "                clean_data.append(new_data)\n",
    "    return(pd.DataFrame(clean_data))\n",
    "\n",
    "df = clean_data_fn(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f230f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def removeStopWords(description):\n",
    "    text_tokens = word_tokenize(description)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    print(\"in\")\n",
    "    return (\" \").join(tokens_without_sw)\n",
    "\n",
    "df[\"coDescription\"] = df[\"coDescription\"].apply(removeStopWords)\n",
    "df[\"coDescription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a04042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def nltk2wn_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:                    \n",
    "        return None\n",
    "    \n",
    "def lemmatize_sentence(sentence):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))    \n",
    "    wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
    "    res_words = []\n",
    "    for word, tag in wn_tagged:\n",
    "        if tag is None:                        \n",
    "            res_words.append(word)\n",
    "        else:\n",
    "            res_words.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(res_words)\n",
    "\n",
    "lemma_desc = df[\"coDescription\"].apply(lemmatize_sentence)\n",
    "df[\"coDescription_lemmatized\"] = lemma_desc\n",
    "df[\"coDescription_lemmatized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a540255",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cd3c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accessionNumber</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>reportingDate</th>\n",
       "      <th>financialEntity</th>\n",
       "      <th>htmlFile</th>\n",
       "      <th>coDescription</th>\n",
       "      <th>CIK</th>\n",
       "      <th>name</th>\n",
       "      <th>countryinc</th>\n",
       "      <th>cityma</th>\n",
       "      <th>SIC</th>\n",
       "      <th>SIC_desc</th>\n",
       "      <th>coDescription_lemmatized</th>\n",
       "      <th>coDescription_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0001441816-18-000028</td>\n",
       "      <td>2018-03-30 20:12:23 UTC</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>financialEntities/params;cik=1441816</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/144181...</td>\n",
       "      <td>mongodb is the leading modern, general purpose...</td>\n",
       "      <td>1441816</td>\n",
       "      <td>MONGODB, INC.</td>\n",
       "      <td>US</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "      <td>mongodb is the leading modern , general purpos...</td>\n",
       "      <td>mongodb leading modern general purpose databas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0001108524-18-000011</td>\n",
       "      <td>2018-03-09 22:01:46 UTC</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>financialEntities/params;cik=1108524</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/110852...</td>\n",
       "      <td>salesforce is a global leader in customer rela...</td>\n",
       "      <td>1108524</td>\n",
       "      <td>SALESFORCE COM INC</td>\n",
       "      <td>US</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "      <td>salesforce is a global leader in customer rela...</td>\n",
       "      <td>salesforce global leader customer relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0001353283-18-000004</td>\n",
       "      <td>2018-03-30 21:21:46 UTC</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>financialEntities/params;cik=1353283</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/135328...</td>\n",
       "      <td>splunk provides innovative software solutions ...</td>\n",
       "      <td>1353283</td>\n",
       "      <td>SPLUNK INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "      <td>splunk provides innovative software solution t...</td>\n",
       "      <td>splunk provides innovative software solution e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0001660134-18-000007</td>\n",
       "      <td>2018-03-12 20:45:43 UTC</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>financialEntities/params;cik=1660134</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/166013...</td>\n",
       "      <td>okta is the leading independent provider of id...</td>\n",
       "      <td>1660134</td>\n",
       "      <td>OKTA, INC.</td>\n",
       "      <td>US</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "      <td>okta is the leading independent provider of id...</td>\n",
       "      <td>okta leading independent provider identity ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0001564590-18-007164</td>\n",
       "      <td>2018-03-29 21:34:05 UTC</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>financialEntities/params;cik=1393052</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/139305...</td>\n",
       "      <td>veeva is a leading provider of industry cloud ...</td>\n",
       "      <td>1393052</td>\n",
       "      <td>VEEVA SYSTEMS INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PLEASANTON</td>\n",
       "      <td>7372</td>\n",
       "      <td>Prepackaged Software (mass reproduction of sof...</td>\n",
       "      <td>veeva is a leading provider of industry cloud ...</td>\n",
       "      <td>veeva leading provider industry cloud solution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>1114</td>\n",
       "      <td>0001595527-19-000005</td>\n",
       "      <td>2019-03-15 12:45:38 UTC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>financialEntities/params;cik=1595527</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/159552...</td>\n",
       "      <td>ationwe were incorporated on december 19, 2013...</td>\n",
       "      <td>1595527</td>\n",
       "      <td>AMERICAN REALTY CAPITAL NEW YORK CITY REIT, INC.</td>\n",
       "      <td>US</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>6798</td>\n",
       "      <td>Real Estate Investment Trusts</td>\n",
       "      <td>ationwe were incorporated on december 19 , 201...</td>\n",
       "      <td>ationwe incorporated december maryland corpora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>1115</td>\n",
       "      <td>0001144204-19-016652</td>\n",
       "      <td>2019-03-28 20:28:30 UTC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>financialEntities/params;cik=1130166</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/113016...</td>\n",
       "      <td>llowing business section contains forward-look...</td>\n",
       "      <td>1130166</td>\n",
       "      <td>CYCLACEL PHARMACEUTICALS, INC.</td>\n",
       "      <td>US</td>\n",
       "      <td>BERKELEY HEIGHTS</td>\n",
       "      <td>2834</td>\n",
       "      <td>Pharmaceutical Preparations</td>\n",
       "      <td>llowing business section contains forward-look...</td>\n",
       "      <td>llowing business section contains statement ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>1117</td>\n",
       "      <td>0001555280-19-000041</td>\n",
       "      <td>2019-02-14 22:08:33 UTC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>financialEntities/params;cik=1555280</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/155528...</td>\n",
       "      <td>ts.costs and expenses costs of sales consist p...</td>\n",
       "      <td>1555280</td>\n",
       "      <td>ZOETIS INC.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARSIPPANY</td>\n",
       "      <td>2834</td>\n",
       "      <td>Pharmaceutical Preparations</td>\n",
       "      <td>ts.costs and expense cost of sale consist prim...</td>\n",
       "      <td>expense cost sale consist primarily cost mater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>1121</td>\n",
       "      <td>0001479094-19-000006</td>\n",
       "      <td>2019-02-13 21:22:54 UTC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>financialEntities/params;cik=1479094</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/147909...</td>\n",
       "      <td>certain definitionsin this report:we define ga...</td>\n",
       "      <td>1479094</td>\n",
       "      <td>STAG INDUSTRIAL, INC.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOSTON</td>\n",
       "      <td>6798</td>\n",
       "      <td>Real Estate Investment Trusts</td>\n",
       "      <td>certain definitionsin this report : we define ...</td>\n",
       "      <td>certain definitionsin report define gaap gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>1123</td>\n",
       "      <td>0001628280-19-001771</td>\n",
       "      <td>2019-02-22 22:02:40 UTC</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>financialEntities/params;cik=1101239</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/110123...</td>\n",
       "      <td>the words equinix, we, our, ours, us and the c...</td>\n",
       "      <td>1101239</td>\n",
       "      <td>EQUINIX INC</td>\n",
       "      <td>US</td>\n",
       "      <td>REDWOOD CITY</td>\n",
       "      <td>6798</td>\n",
       "      <td>Real Estate Investment Trusts</td>\n",
       "      <td>the word equinix , we , our , ours , u and the...</td>\n",
       "      <td>word equinix u company refer equinix statement...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       accessionNumber               filingDate reportingDate  \\\n",
       "0             0  0001441816-18-000028  2018-03-30 20:12:23 UTC    2018-02-01   \n",
       "1             1  0001108524-18-000011  2018-03-09 22:01:46 UTC    2018-02-01   \n",
       "2             3  0001353283-18-000004  2018-03-30 21:21:46 UTC    2018-02-01   \n",
       "3             4  0001660134-18-000007  2018-03-12 20:45:43 UTC    2018-02-01   \n",
       "4             5  0001564590-18-007164  2018-03-29 21:34:05 UTC    2018-02-01   \n",
       "..          ...                   ...                      ...           ...   \n",
       "670        1114  0001595527-19-000005  2019-03-15 12:45:38 UTC    2019-01-01   \n",
       "671        1115  0001144204-19-016652  2019-03-28 20:28:30 UTC    2019-01-01   \n",
       "672        1117  0001555280-19-000041  2019-02-14 22:08:33 UTC    2019-01-01   \n",
       "673        1121  0001479094-19-000006  2019-02-13 21:22:54 UTC    2019-01-01   \n",
       "674        1123  0001628280-19-001771  2019-02-22 22:02:40 UTC    2019-01-01   \n",
       "\n",
       "                          financialEntity  \\\n",
       "0    financialEntities/params;cik=1441816   \n",
       "1    financialEntities/params;cik=1108524   \n",
       "2    financialEntities/params;cik=1353283   \n",
       "3    financialEntities/params;cik=1660134   \n",
       "4    financialEntities/params;cik=1393052   \n",
       "..                                    ...   \n",
       "670  financialEntities/params;cik=1595527   \n",
       "671  financialEntities/params;cik=1130166   \n",
       "672  financialEntities/params;cik=1555280   \n",
       "673  financialEntities/params;cik=1479094   \n",
       "674  financialEntities/params;cik=1101239   \n",
       "\n",
       "                                              htmlFile  \\\n",
       "0    https://www.sec.gov/Archives/edgar/data/144181...   \n",
       "1    https://www.sec.gov/Archives/edgar/data/110852...   \n",
       "2    https://www.sec.gov/Archives/edgar/data/135328...   \n",
       "3    https://www.sec.gov/Archives/edgar/data/166013...   \n",
       "4    https://www.sec.gov/Archives/edgar/data/139305...   \n",
       "..                                                 ...   \n",
       "670  https://www.sec.gov/Archives/edgar/data/159552...   \n",
       "671  https://www.sec.gov/Archives/edgar/data/113016...   \n",
       "672  https://www.sec.gov/Archives/edgar/data/155528...   \n",
       "673  https://www.sec.gov/Archives/edgar/data/147909...   \n",
       "674  https://www.sec.gov/Archives/edgar/data/110123...   \n",
       "\n",
       "                                         coDescription      CIK  \\\n",
       "0    mongodb is the leading modern, general purpose...  1441816   \n",
       "1    salesforce is a global leader in customer rela...  1108524   \n",
       "2    splunk provides innovative software solutions ...  1353283   \n",
       "3    okta is the leading independent provider of id...  1660134   \n",
       "4    veeva is a leading provider of industry cloud ...  1393052   \n",
       "..                                                 ...      ...   \n",
       "670  ationwe were incorporated on december 19, 2013...  1595527   \n",
       "671  llowing business section contains forward-look...  1130166   \n",
       "672  ts.costs and expenses costs of sales consist p...  1555280   \n",
       "673  certain definitionsin this report:we define ga...  1479094   \n",
       "674  the words equinix, we, our, ours, us and the c...  1101239   \n",
       "\n",
       "                                                 name countryinc  \\\n",
       "0                                       MONGODB, INC.         US   \n",
       "1                                  SALESFORCE COM INC         US   \n",
       "2                                          SPLUNK INC        NaN   \n",
       "3                                          OKTA, INC.         US   \n",
       "4                                   VEEVA SYSTEMS INC        NaN   \n",
       "..                                                ...        ...   \n",
       "670  AMERICAN REALTY CAPITAL NEW YORK CITY REIT, INC.         US   \n",
       "671                    CYCLACEL PHARMACEUTICALS, INC.         US   \n",
       "672                                       ZOETIS INC.        NaN   \n",
       "673                             STAG INDUSTRIAL, INC.        NaN   \n",
       "674                                       EQUINIX INC         US   \n",
       "\n",
       "               cityma   SIC  \\\n",
       "0            NEW YORK  7372   \n",
       "1       SAN FRANCISCO  7372   \n",
       "2       SAN FRANCISCO  7372   \n",
       "3       SAN FRANCISCO  7372   \n",
       "4          PLEASANTON  7372   \n",
       "..                ...   ...   \n",
       "670          NEW YORK  6798   \n",
       "671  BERKELEY HEIGHTS  2834   \n",
       "672        PARSIPPANY  2834   \n",
       "673            BOSTON  6798   \n",
       "674      REDWOOD CITY  6798   \n",
       "\n",
       "                                              SIC_desc  \\\n",
       "0    Prepackaged Software (mass reproduction of sof...   \n",
       "1    Prepackaged Software (mass reproduction of sof...   \n",
       "2    Prepackaged Software (mass reproduction of sof...   \n",
       "3    Prepackaged Software (mass reproduction of sof...   \n",
       "4    Prepackaged Software (mass reproduction of sof...   \n",
       "..                                                 ...   \n",
       "670                      Real Estate Investment Trusts   \n",
       "671                        Pharmaceutical Preparations   \n",
       "672                        Pharmaceutical Preparations   \n",
       "673                      Real Estate Investment Trusts   \n",
       "674                      Real Estate Investment Trusts   \n",
       "\n",
       "                              coDescription_lemmatized  \\\n",
       "0    mongodb is the leading modern , general purpos...   \n",
       "1    salesforce is a global leader in customer rela...   \n",
       "2    splunk provides innovative software solution t...   \n",
       "3    okta is the leading independent provider of id...   \n",
       "4    veeva is a leading provider of industry cloud ...   \n",
       "..                                                 ...   \n",
       "670  ationwe were incorporated on december 19 , 201...   \n",
       "671  llowing business section contains forward-look...   \n",
       "672  ts.costs and expense cost of sale consist prim...   \n",
       "673  certain definitionsin this report : we define ...   \n",
       "674  the word equinix , we , our , ours , u and the...   \n",
       "\n",
       "                               coDescription_stopwords  \n",
       "0    mongodb leading modern general purpose databas...  \n",
       "1    salesforce global leader customer relationship...  \n",
       "2    splunk provides innovative software solution e...  \n",
       "3    okta leading independent provider identity ent...  \n",
       "4    veeva leading provider industry cloud solution...  \n",
       "..                                                 ...  \n",
       "670  ationwe incorporated december maryland corpora...  \n",
       "671  llowing business section contains statement ac...  \n",
       "672  expense cost sale consist primarily cost mater...  \n",
       "673  certain definitionsin report define gaap gener...  \n",
       "674  word equinix u company refer equinix statement...  \n",
       "\n",
       "[618 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df.drop_duplicates(subset = \"name\", keep=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e54a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.22.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.4.0)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.8.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.29.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maryx\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\maryx\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\maryx\\AppData\\Local\\Temp\\tfhub_modules\\063d866c06683311b44b4992fd46003be952409c\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 install seaborn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m embed \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:106\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    103\u001b[0m   obj \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload_v2(\n\u001b[0;32m    104\u001b[0m       module_path, tags\u001b[38;5;241m=\u001b[39mtags, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m   obj \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m obj\u001b[38;5;241m.\u001b[39m_is_hub_module_v1 \u001b[38;5;241m=\u001b[39m is_hub_module_v1  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:936\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model.load_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(export_dir, tags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    847\u001b[0m   \u001b[38;5;124;03m\"\"\"Load a SavedModel from `export_dir`.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m  Signatures associated with the SavedModel are available as functions:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m    ValueError: If `tags` don't match a MetaGraph in the SavedModel.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 936\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mload_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:949\u001b[0m, in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m    948\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 949\u001b[0m     \u001b[43mloader_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    952\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    953\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:57\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     45\u001b[0m   \u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     60\u001b[0m       saved_model_utils\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     61\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     62\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\maryx\\AppData\\Local\\Temp\\tfhub_modules\\063d866c06683311b44b4992fd46003be952409c\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "!pip3 install seaborn\n",
    "import seaborn as sns\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(df[\"coDescription_stopwords\"])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a840a",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "      corr,\n",
    "      xticklabels=labels,\n",
    "      yticklabels=labels,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "plot_similarity(df[\"name\"][:20],embeddings[:20], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece38133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "\n",
    "# Referenced from my CSCD25 course\n",
    "def visualize_pca(vectors, index):\n",
    "    multi_index = pd.MultiIndex.from_frame(index, names=[\"name\", \"industry\"])\n",
    "    \n",
    "    pca = PCA(n_components = 50)\n",
    "    pca_embedding = pca.fit_transform(vectors)\n",
    "    pca_embedding = pd.DataFrame(pca_embedding, index = multi_index)\n",
    "    \n",
    "    fig = px.scatter(pca_embedding, x =0 , y = 1, hover_data={\"name\": pca_embedding.index.get_level_values(0),\n",
    "                                                              \"industry\": pca_embedding.index.get_level_values(1)},\n",
    "                     color = pca_embedding.index.get_level_values(1), width=1200, height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    return [pca, pca_embedding]\n",
    "\n",
    "plot_pca = visualize_pca(embeddings, df.loc[:,[\"name\",\"SIC_desc\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(plot_pca[1], x =0 , y = 1, z = 2, hover_data={\"name\": plot_pca[1].index.get_level_values(0),\n",
    "                                                              \"industry\": plot_pca[1].index.get_level_values(1)},\n",
    "                    color = plot_pca[1].index.get_level_values(1), width=1200, height=700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    \n",
    "corr = np.inner(embeddings, embeddings)\n",
    "len(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = pd.DataFrame(embeddings)\n",
    "embedding_matrix.index = df[\"name\"]\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b09109",
   "metadata": {},
   "source": [
    "## Similarity Matrix\n",
    "USE gives normalized embeddings, so the inner product of encodings can be treated as a similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = np.matmul(embedding_matrix, embedding_matrix.T)\n",
    "np.fill_diagonal(dot_product.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f554303",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product.index = df[\"SIC_desc\"]\n",
    "dot_product.columns = df[\"SIC_desc\"]\n",
    "dot_product_df = pd.DataFrame(dot_product.idxmax(axis=1))\n",
    "dot_product_df.reset_index(level=0, inplace=True)\n",
    "dot_product_df.columns = [\"desc1\",\"desc2\"]\n",
    "dot_product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of correct category predictions: \")\n",
    "print(np.sum(np.where(dot_product_df.iloc[:,1] == dot_product_df.iloc[:,0], 1, 0))/len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c57565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c1e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

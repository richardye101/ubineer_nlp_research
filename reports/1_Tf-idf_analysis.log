Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import Pipeline

df = pd.read_csv("https://mega.nz/file/2dIEQBhQ#OvgE2YB2YdkplKt7-3unbEn7HTVZo3JbJAsv1NfFHeg")
pipe = Pipeline([('count', CountVectorizer(ngram_range = (2,4),
                                           stop_words = 'english', max_features = 400)),
                  ('tfidf', TfidfTransformer())]).fit(df)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mParserError[0m                               Traceback (most recent call last)
Input [0;32mIn [1][0m, in [0;36m<cell line: 7>[0;34m()[0m
[1;32m      4[0m [38;5;28;01mfrom[39;00m [38;5;21;01msklearn[39;00m[38;5;21;01m.[39;00m[38;5;21;01mfeature_extraction[39;00m[38;5;21;01m.[39;00m[38;5;21;01mtext[39;00m [38;5;28;01mimport[39;00m CountVectorizer
[1;32m      5[0m [38;5;28;01mfrom[39;00m [38;5;21;01msklearn[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpipeline[39;00m [38;5;28;01mimport[39;00m Pipeline
[0;32m----> 7[0m df [38;5;241m=[39m [43mpd[49m[38;5;241;43m.[39;49m[43mread_csv[49m[43m([49m[38;5;124;43m"[39;49m[38;5;124;43mhttps://mega.nz/file/2dIEQBhQ#OvgE2YB2YdkplKt7-3unbEn7HTVZo3JbJAsv1NfFHeg[39;49m[38;5;124;43m"[39;49m[43m)[49m
[1;32m      8[0m pipe [38;5;241m=[39m Pipeline([([38;5;124m'[39m[38;5;124mcount[39m[38;5;124m'[39m, CountVectorizer(ngram_range [38;5;241m=[39m ([38;5;241m2[39m,[38;5;241m4[39m),
[1;32m      9[0m                                            stop_words [38;5;241m=[39m [38;5;124m'[39m[38;5;124menglish[39m[38;5;124m'[39m, max_features [38;5;241m=[39m [38;5;241m400[39m)),
[1;32m     10[0m                   ([38;5;124m'[39m[38;5;124mtfidf[39m[38;5;124m'[39m, TfidfTransformer())])[38;5;241m.[39mfit(df)

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/util/_decorators.py:311[0m, in [0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper[0;34m(*args, **kwargs)[0m
[1;32m    305[0m [38;5;28;01mif[39;00m [38;5;28mlen[39m(args) [38;5;241m>[39m num_allow_args:
[1;32m    306[0m     warnings[38;5;241m.[39mwarn(
[1;32m    307[0m         msg[38;5;241m.[39mformat(arguments[38;5;241m=[39marguments),
[1;32m    308[0m         [38;5;167;01mFutureWarning[39;00m,
[1;32m    309[0m         stacklevel[38;5;241m=[39mstacklevel,
[1;32m    310[0m     )
[0;32m--> 311[0m [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680[0m, in [0;36mread_csv[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)[0m
[1;32m    665[0m kwds_defaults [38;5;241m=[39m _refine_defaults_read(
[1;32m    666[0m     dialect,
[1;32m    667[0m     delimiter,
[0;32m   (...)[0m
[1;32m    676[0m     defaults[38;5;241m=[39m{[38;5;124m"[39m[38;5;124mdelimiter[39m[38;5;124m"[39m: [38;5;124m"[39m[38;5;124m,[39m[38;5;124m"[39m},
[1;32m    677[0m )
[1;32m    678[0m kwds[38;5;241m.[39mupdate(kwds_defaults)
[0;32m--> 680[0m [38;5;28;01mreturn[39;00m [43m_read[49m[43m([49m[43mfilepath_or_buffer[49m[43m,[49m[43m [49m[43mkwds[49m[43m)[49m

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581[0m, in [0;36m_read[0;34m(filepath_or_buffer, kwds)[0m
[1;32m    578[0m     [38;5;28;01mreturn[39;00m parser
[1;32m    580[0m [38;5;28;01mwith[39;00m parser:
[0;32m--> 581[0m     [38;5;28;01mreturn[39;00m [43mparser[49m[38;5;241;43m.[39;49m[43mread[49m[43m([49m[43mnrows[49m[43m)[49m

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1250[0m, in [0;36mTextFileReader.read[0;34m(self, nrows)[0m
[1;32m   1248[0m nrows [38;5;241m=[39m validate_integer([38;5;124m"[39m[38;5;124mnrows[39m[38;5;124m"[39m, nrows)
[1;32m   1249[0m [38;5;28;01mtry[39;00m:
[0;32m-> 1250[0m     index, columns, col_dict [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_engine[49m[38;5;241;43m.[39;49m[43mread[49m[43m([49m[43mnrows[49m[43m)[49m
[1;32m   1251[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m:
[1;32m   1252[0m     [38;5;28mself[39m[38;5;241m.[39mclose()

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225[0m, in [0;36mCParserWrapper.read[0;34m(self, nrows)[0m
[1;32m    223[0m [38;5;28;01mtry[39;00m:
[1;32m    224[0m     [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mlow_memory:
[0;32m--> 225[0m         chunks [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_reader[49m[38;5;241;43m.[39;49m[43mread_low_memory[49m[43m([49m[43mnrows[49m[43m)[49m
[1;32m    226[0m         [38;5;66;03m# destructive to chunks[39;00m
[1;32m    227[0m         data [38;5;241m=[39m _concatenate_chunks(chunks)

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805[0m, in [0;36mpandas._libs.parsers.TextReader.read_low_memory[0;34m()[0m

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:861[0m, in [0;36mpandas._libs.parsers.TextReader._read_rows[0;34m()[0m

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:847[0m, in [0;36mpandas._libs.parsers.TextReader._tokenize_rows[0;34m()[0m

File [0;32m/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1960[0m, in [0;36mpandas._libs.parsers.raise_parser_error[0;34m()[0m

[0;31mParserError[0m: Error tokenizing data. C error: Expected 1 fields in line 13, saw 2

ParserError: Error tokenizing data. C error: Expected 1 fields in line 13, saw 2



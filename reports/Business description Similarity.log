Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/usr/local/lib/python3.9/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/usr/local/lib/python3.9/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 642, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/usr/local/lib/python3.9/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
#tokenizing words
nltk_tokens_okta = nltk.word_tokenize(df_okta["BD"][-1])
tokens_okta = [token.lower() for token in nltk_tokens_okta]
nltk_tokens_sail = nltk.word_tokenize(df_sail["BD"][-1])
tokens_sail = [token.lower() for token in nltk_tokens_sail]
nltk_tokens_aapl = nltk.word_tokenize(df_aapl["BD"][-1])
tokens_aapl = [token.lower() for token in nltk_tokens_aapl]

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mNameError[0m                                 Traceback (most recent call last)
Input [0;32mIn [10][0m, in [0;36m<cell line: 2>[0;34m()[0m
[1;32m      1[0m [38;5;66;03m#tokenizing words[39;00m
[0;32m----> 2[0m nltk_tokens_okta [38;5;241m=[39m nltk[38;5;241m.[39mword_tokenize([43mdf_okta[49m[[38;5;124m"[39m[38;5;124mBD[39m[38;5;124m"[39m][[38;5;241m-[39m[38;5;241m1[39m])
[1;32m      3[0m tokens_okta [38;5;241m=[39m [token[38;5;241m.[39mlower() [38;5;28;01mfor[39;00m token [38;5;129;01min[39;00m nltk_tokens_okta]
[1;32m      4[0m nltk_tokens_sail [38;5;241m=[39m nltk[38;5;241m.[39mword_tokenize(df_sail[[38;5;124m"[39m[38;5;124mBD[39m[38;5;124m"[39m][[38;5;241m-[39m[38;5;241m1[39m])

[0;31mNameError[0m: name 'df_okta' is not defined
NameError: name 'df_okta' is not defined

